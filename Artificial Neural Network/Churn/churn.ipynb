{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação das bibliotecas.\n",
    "\n",
    "#Para manipulação\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "#Para Visualização.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import mplcursors\n",
    "\n",
    "#Para Analises e Modelos.\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "#configurações.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv', sep=',')\n",
    "X = df.iloc[:,3:13].values\n",
    "y = df.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 619, ..., 1, 1, 101348.88],\n",
       "       [0.0, 1.0, 608, ..., 0, 1, 112542.58],\n",
       "       [0.0, 0.0, 502, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [0.0, 0.0, 709, ..., 0, 1, 42085.58],\n",
       "       [1.0, 0.0, 772, ..., 1, 0, 92888.52],\n",
       "       [0.0, 0.0, 792, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mudando dados object.\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])\n",
    "\n",
    "\n",
    "ohc = make_column_transformer((OneHotEncoder(categories='auto', sparse=False), [1]), remainder='passthrough')\n",
    "X = ohc.fit_transform(X)\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Standart Scaler.\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da rede neural\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "534/534 [==============================] - 1s 974us/step - loss: 0.5164 - accuracy: 0.7936\n",
      "Epoch 2/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4337 - accuracy: 0.7945\n",
      "Epoch 3/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4284 - accuracy: 0.7945\n",
      "Epoch 4/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4247 - accuracy: 0.7945\n",
      "Epoch 5/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4212 - accuracy: 0.8154\n",
      "Epoch 6/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4194 - accuracy: 0.8250\n",
      "Epoch 7/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4173 - accuracy: 0.8275\n",
      "Epoch 8/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.8304\n",
      "Epoch 9/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4149 - accuracy: 0.8319\n",
      "Epoch 10/150\n",
      "534/534 [==============================] - 1s 959us/step - loss: 0.4137 - accuracy: 0.8320\n",
      "Epoch 11/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4127 - accuracy: 0.8331\n",
      "Epoch 12/150\n",
      "534/534 [==============================] - 1s 987us/step - loss: 0.4119 - accuracy: 0.8340\n",
      "Epoch 13/150\n",
      "534/534 [==============================] - 0s 931us/step - loss: 0.4111 - accuracy: 0.8347\n",
      "Epoch 14/150\n",
      "534/534 [==============================] - 1s 998us/step - loss: 0.4103 - accuracy: 0.8350\n",
      "Epoch 15/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4099 - accuracy: 0.8346\n",
      "Epoch 16/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.8346\n",
      "Epoch 17/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4087 - accuracy: 0.8356\n",
      "Epoch 18/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4087 - accuracy: 0.8355\n",
      "Epoch 19/150\n",
      "534/534 [==============================] - 0s 893us/step - loss: 0.4082 - accuracy: 0.8350\n",
      "Epoch 20/150\n",
      "534/534 [==============================] - 1s 947us/step - loss: 0.4080 - accuracy: 0.8360\n",
      "Epoch 21/150\n",
      "534/534 [==============================] - 1s 995us/step - loss: 0.4074 - accuracy: 0.8346\n",
      "Epoch 22/150\n",
      "534/534 [==============================] - 0s 937us/step - loss: 0.4074 - accuracy: 0.8356\n",
      "Epoch 23/150\n",
      "534/534 [==============================] - 0s 862us/step - loss: 0.4071 - accuracy: 0.8351\n",
      "Epoch 24/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4071 - accuracy: 0.8347\n",
      "Epoch 25/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4067 - accuracy: 0.8347\n",
      "Epoch 26/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8360\n",
      "Epoch 27/150\n",
      "534/534 [==============================] - 1s 993us/step - loss: 0.4059 - accuracy: 0.8353\n",
      "Epoch 28/150\n",
      "534/534 [==============================] - 1s 985us/step - loss: 0.4056 - accuracy: 0.8354\n",
      "Epoch 29/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4058 - accuracy: 0.8345\n",
      "Epoch 30/150\n",
      "534/534 [==============================] - 1s 983us/step - loss: 0.4056 - accuracy: 0.8364\n",
      "Epoch 31/150\n",
      "534/534 [==============================] - 1s 983us/step - loss: 0.4054 - accuracy: 0.8340\n",
      "Epoch 32/150\n",
      "534/534 [==============================] - 1s 973us/step - loss: 0.4058 - accuracy: 0.8345\n",
      "Epoch 33/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4055 - accuracy: 0.8360\n",
      "Epoch 34/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8332\n",
      "Epoch 35/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4051 - accuracy: 0.8350\n",
      "Epoch 36/150\n",
      "534/534 [==============================] - 1s 970us/step - loss: 0.4049 - accuracy: 0.8342\n",
      "Epoch 37/150\n",
      "534/534 [==============================] - 1s 974us/step - loss: 0.4041 - accuracy: 0.8347\n",
      "Epoch 38/150\n",
      "534/534 [==============================] - 0s 910us/step - loss: 0.4032 - accuracy: 0.8363\n",
      "Epoch 39/150\n",
      "534/534 [==============================] - 1s 942us/step - loss: 0.4028 - accuracy: 0.8350\n",
      "Epoch 40/150\n",
      "534/534 [==============================] - 1s 982us/step - loss: 0.4023 - accuracy: 0.8346\n",
      "Epoch 41/150\n",
      "534/534 [==============================] - 1s 943us/step - loss: 0.4022 - accuracy: 0.8344\n",
      "Epoch 42/150\n",
      "534/534 [==============================] - 1s 952us/step - loss: 0.4019 - accuracy: 0.8361\n",
      "Epoch 43/150\n",
      "534/534 [==============================] - 1s 965us/step - loss: 0.4012 - accuracy: 0.8361\n",
      "Epoch 44/150\n",
      "534/534 [==============================] - 1s 952us/step - loss: 0.4008 - accuracy: 0.8350\n",
      "Epoch 45/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8357\n",
      "Epoch 46/150\n",
      "534/534 [==============================] - 0s 918us/step - loss: 0.4003 - accuracy: 0.8356\n",
      "Epoch 47/150\n",
      "534/534 [==============================] - 1s 970us/step - loss: 0.3998 - accuracy: 0.8354\n",
      "Epoch 48/150\n",
      "534/534 [==============================] - 1s 941us/step - loss: 0.3994 - accuracy: 0.8359\n",
      "Epoch 49/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3987 - accuracy: 0.8359\n",
      "Epoch 50/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8374\n",
      "Epoch 51/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3987 - accuracy: 0.8360\n",
      "Epoch 52/150\n",
      "534/534 [==============================] - 1s 955us/step - loss: 0.3983 - accuracy: 0.8349\n",
      "Epoch 53/150\n",
      "534/534 [==============================] - 1s 946us/step - loss: 0.3982 - accuracy: 0.8366\n",
      "Epoch 54/150\n",
      "534/534 [==============================] - 1s 953us/step - loss: 0.3979 - accuracy: 0.8360\n",
      "Epoch 55/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8367\n",
      "Epoch 56/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3971 - accuracy: 0.8360\n",
      "Epoch 57/150\n",
      "534/534 [==============================] - 1s 948us/step - loss: 0.3971 - accuracy: 0.8386\n",
      "Epoch 58/150\n",
      "534/534 [==============================] - 1s 951us/step - loss: 0.3966 - accuracy: 0.8375\n",
      "Epoch 59/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3968 - accuracy: 0.8370\n",
      "Epoch 60/150\n",
      "534/534 [==============================] - 1s 971us/step - loss: 0.3964 - accuracy: 0.8379\n",
      "Epoch 61/150\n",
      "534/534 [==============================] - 1s 955us/step - loss: 0.3962 - accuracy: 0.8375\n",
      "Epoch 62/150\n",
      "534/534 [==============================] - 0s 923us/step - loss: 0.3961 - accuracy: 0.8360\n",
      "Epoch 63/150\n",
      "534/534 [==============================] - 1s 955us/step - loss: 0.3958 - accuracy: 0.8370\n",
      "Epoch 64/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3959 - accuracy: 0.8371\n",
      "Epoch 65/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8381\n",
      "Epoch 66/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3952 - accuracy: 0.8366\n",
      "Epoch 67/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8364\n",
      "Epoch 68/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3947 - accuracy: 0.8375\n",
      "Epoch 69/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3949 - accuracy: 0.8381\n",
      "Epoch 70/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.8374\n",
      "Epoch 71/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8374\n",
      "Epoch 72/150\n",
      "534/534 [==============================] - 1s 989us/step - loss: 0.3945 - accuracy: 0.8384\n",
      "Epoch 73/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3937 - accuracy: 0.8388\n",
      "Epoch 74/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8393\n",
      "Epoch 75/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3934 - accuracy: 0.8385\n",
      "Epoch 76/150\n",
      "534/534 [==============================] - 1s 939us/step - loss: 0.3930 - accuracy: 0.8390\n",
      "Epoch 77/150\n",
      "534/534 [==============================] - 1s 985us/step - loss: 0.3931 - accuracy: 0.8399\n",
      "Epoch 78/150\n",
      "534/534 [==============================] - 0s 929us/step - loss: 0.3917 - accuracy: 0.8403\n",
      "Epoch 79/150\n",
      "534/534 [==============================] - 0s 936us/step - loss: 0.3922 - accuracy: 0.8399\n",
      "Epoch 80/150\n",
      "534/534 [==============================] - 1s 965us/step - loss: 0.3914 - accuracy: 0.8399\n",
      "Epoch 81/150\n",
      "534/534 [==============================] - 1s 985us/step - loss: 0.3912 - accuracy: 0.8407\n",
      "Epoch 82/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8407\n",
      "Epoch 83/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3893 - accuracy: 0.8409\n",
      "Epoch 84/150\n",
      "534/534 [==============================] - 1s 959us/step - loss: 0.3874 - accuracy: 0.8429\n",
      "Epoch 85/150\n",
      "534/534 [==============================] - 1s 986us/step - loss: 0.3858 - accuracy: 0.8421\n",
      "Epoch 86/150\n",
      "534/534 [==============================] - 1s 946us/step - loss: 0.3843 - accuracy: 0.8429\n",
      "Epoch 87/150\n",
      "534/534 [==============================] - 0s 920us/step - loss: 0.3809 - accuracy: 0.8439\n",
      "Epoch 88/150\n",
      "534/534 [==============================] - 1s 968us/step - loss: 0.3780 - accuracy: 0.8443\n",
      "Epoch 89/150\n",
      "534/534 [==============================] - 0s 936us/step - loss: 0.3741 - accuracy: 0.8446\n",
      "Epoch 90/150\n",
      "534/534 [==============================] - 1s 984us/step - loss: 0.3716 - accuracy: 0.8446\n",
      "Epoch 91/150\n",
      "534/534 [==============================] - 0s 892us/step - loss: 0.3676 - accuracy: 0.8471\n",
      "Epoch 92/150\n",
      "534/534 [==============================] - 0s 907us/step - loss: 0.3657 - accuracy: 0.8468\n",
      "Epoch 93/150\n",
      "534/534 [==============================] - 0s 877us/step - loss: 0.3637 - accuracy: 0.8478\n",
      "Epoch 94/150\n",
      "534/534 [==============================] - 1s 957us/step - loss: 0.3613 - accuracy: 0.8487\n",
      "Epoch 95/150\n",
      "534/534 [==============================] - 1s 995us/step - loss: 0.3592 - accuracy: 0.8510\n",
      "Epoch 96/150\n",
      "534/534 [==============================] - 1s 939us/step - loss: 0.3572 - accuracy: 0.8519\n",
      "Epoch 97/150\n",
      "534/534 [==============================] - 1s 959us/step - loss: 0.3553 - accuracy: 0.8494\n",
      "Epoch 98/150\n",
      "534/534 [==============================] - 1s 959us/step - loss: 0.3554 - accuracy: 0.8522\n",
      "Epoch 99/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3528 - accuracy: 0.8519\n",
      "Epoch 100/150\n",
      "534/534 [==============================] - 1s 955us/step - loss: 0.3518 - accuracy: 0.8521\n",
      "Epoch 101/150\n",
      "534/534 [==============================] - 1s 948us/step - loss: 0.3507 - accuracy: 0.8551\n",
      "Epoch 102/150\n",
      "534/534 [==============================] - 0s 923us/step - loss: 0.3498 - accuracy: 0.8539\n",
      "Epoch 103/150\n",
      "534/534 [==============================] - 1s 951us/step - loss: 0.3493 - accuracy: 0.8524\n",
      "Epoch 104/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3496 - accuracy: 0.8536\n",
      "Epoch 105/150\n",
      "534/534 [==============================] - 0s 863us/step - loss: 0.3481 - accuracy: 0.8562\n",
      "Epoch 106/150\n",
      "534/534 [==============================] - 0s 877us/step - loss: 0.3484 - accuracy: 0.8551\n",
      "Epoch 107/150\n",
      "534/534 [==============================] - 0s 909us/step - loss: 0.3471 - accuracy: 0.8566\n",
      "Epoch 108/150\n",
      "534/534 [==============================] - 0s 924us/step - loss: 0.3475 - accuracy: 0.8571\n",
      "Epoch 109/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3465 - accuracy: 0.8572\n",
      "Epoch 110/150\n",
      "534/534 [==============================] - 1s 951us/step - loss: 0.3467 - accuracy: 0.8549\n",
      "Epoch 111/150\n",
      "534/534 [==============================] - 1s 969us/step - loss: 0.3460 - accuracy: 0.8551\n",
      "Epoch 112/150\n",
      "534/534 [==============================] - 0s 938us/step - loss: 0.3458 - accuracy: 0.8550\n",
      "Epoch 113/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3452 - accuracy: 0.8569\n",
      "Epoch 114/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3449 - accuracy: 0.8569\n",
      "Epoch 115/150\n",
      "534/534 [==============================] - 1s 969us/step - loss: 0.3445 - accuracy: 0.8583\n",
      "Epoch 116/150\n",
      "534/534 [==============================] - 1s 939us/step - loss: 0.3443 - accuracy: 0.8585\n",
      "Epoch 117/150\n",
      "534/534 [==============================] - 1s 956us/step - loss: 0.3449 - accuracy: 0.8566\n",
      "Epoch 118/150\n",
      "534/534 [==============================] - 1s 998us/step - loss: 0.3441 - accuracy: 0.8575\n",
      "Epoch 119/150\n",
      "534/534 [==============================] - 0s 932us/step - loss: 0.3442 - accuracy: 0.8576\n",
      "Epoch 120/150\n",
      "534/534 [==============================] - 1s 955us/step - loss: 0.3444 - accuracy: 0.8577\n",
      "Epoch 121/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8564\n",
      "Epoch 122/150\n",
      "534/534 [==============================] - 1s 986us/step - loss: 0.3430 - accuracy: 0.8564\n",
      "Epoch 123/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3434 - accuracy: 0.8574\n",
      "Epoch 124/150\n",
      "534/534 [==============================] - 1s 984us/step - loss: 0.3434 - accuracy: 0.8564\n",
      "Epoch 125/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8574\n",
      "Epoch 126/150\n",
      "534/534 [==============================] - 1s 979us/step - loss: 0.3434 - accuracy: 0.8574\n",
      "Epoch 127/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8572\n",
      "Epoch 128/150\n",
      "534/534 [==============================] - 0s 903us/step - loss: 0.3426 - accuracy: 0.8577\n",
      "Epoch 129/150\n",
      "534/534 [==============================] - 0s 922us/step - loss: 0.3429 - accuracy: 0.8576\n",
      "Epoch 130/150\n",
      "534/534 [==============================] - 1s 959us/step - loss: 0.3431 - accuracy: 0.8583\n",
      "Epoch 131/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3429 - accuracy: 0.8583\n",
      "Epoch 132/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3425 - accuracy: 0.8589\n",
      "Epoch 133/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8558\n",
      "Epoch 134/150\n",
      "534/534 [==============================] - 1s 997us/step - loss: 0.3423 - accuracy: 0.8575\n",
      "Epoch 135/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3428 - accuracy: 0.8585\n",
      "Epoch 136/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8596\n",
      "Epoch 137/150\n",
      "534/534 [==============================] - 1s 941us/step - loss: 0.3422 - accuracy: 0.8581\n",
      "Epoch 138/150\n",
      "534/534 [==============================] - 1s 954us/step - loss: 0.3414 - accuracy: 0.8575\n",
      "Epoch 139/150\n",
      "534/534 [==============================] - 1s 937us/step - loss: 0.3423 - accuracy: 0.8591\n",
      "Epoch 140/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3415 - accuracy: 0.8587\n",
      "Epoch 141/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8601\n",
      "Epoch 142/150\n",
      "534/534 [==============================] - 1s 985us/step - loss: 0.3415 - accuracy: 0.8575\n",
      "Epoch 143/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8576\n",
      "Epoch 144/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3415 - accuracy: 0.8597\n",
      "Epoch 145/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3409 - accuracy: 0.8609\n",
      "Epoch 146/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3413 - accuracy: 0.8581\n",
      "Epoch 147/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8609\n",
      "Epoch 148/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8594\n",
      "Epoch 149/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3414 - accuracy: 0.8596\n",
      "Epoch 150/150\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8580\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#Neuronios ocultos.\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11))\n",
    "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
    "#Saida\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "#Definindo as atualizações no treino.\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier = classifier.fit(X_train, y_train, batch_size=15, epochs=150)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8608750104904175"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss = max(classifier.history['accuracy'])\n",
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 877us/step\n"
     ]
    }
   ],
   "source": [
    "#Previsões.\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "cf_matrix = confusion_matrix(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1527</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>80</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True  False\n",
       "True   1527    207\n",
       "False    80    186"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cf_matrix, columns=['True', 'False'], index=['True', 'False'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>15643966</td>\n",
       "      <td>Goforth</td>\n",
       "      <td>616</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>15737452</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>15788218</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>549</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>15661507</td>\n",
       "      <td>Muldrow</td>\n",
       "      <td>587</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>15568982</td>\n",
       "      <td>Hao</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           1    15634602   Hargrave          619    France  Female   42   \n",
       "1           2    15647311       Hill          608     Spain  Female   41   \n",
       "2           3    15619304       Onio          502    France  Female   42   \n",
       "3           4    15701354       Boni          699    France  Female   39   \n",
       "4           5    15737888   Mitchell          850     Spain  Female   43   \n",
       "5           6    15574012        Chu          645     Spain    Male   44   \n",
       "6           7    15592531   Bartlett          822    France    Male   50   \n",
       "7           8    15656148     Obinna          376   Germany  Female   29   \n",
       "8           9    15792365         He          501    France    Male   44   \n",
       "9          10    15592389         H?          684    France    Male   27   \n",
       "10         11    15767821     Bearce          528    France    Male   31   \n",
       "11         12    15737173    Andrews          497     Spain    Male   24   \n",
       "12         13    15632264        Kay          476    France  Female   34   \n",
       "13         14    15691483       Chin          549    France  Female   25   \n",
       "14         15    15600882      Scott          635     Spain  Female   35   \n",
       "15         16    15643966    Goforth          616   Germany    Male   45   \n",
       "16         17    15737452      Romeo          653   Germany    Male   58   \n",
       "17         18    15788218  Henderson          549     Spain  Female   24   \n",
       "18         19    15661507    Muldrow          587     Spain    Male   45   \n",
       "19         20    15568982        Hao          726    France  Female   24   \n",
       "\n",
       "    Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2      0.00              1          1               1   \n",
       "1        1  83807.86              1          0               1   \n",
       "2        8 159660.80              3          1               0   \n",
       "3        1      0.00              2          0               0   \n",
       "4        2 125510.82              1          1               1   \n",
       "5        8 113755.78              2          1               0   \n",
       "6        7      0.00              2          1               1   \n",
       "7        4 115046.74              4          1               0   \n",
       "8        4 142051.07              2          0               1   \n",
       "9        2 134603.88              1          1               1   \n",
       "10       6 102016.72              2          0               0   \n",
       "11       3      0.00              2          1               0   \n",
       "12      10      0.00              2          1               0   \n",
       "13       5      0.00              2          0               0   \n",
       "14       7      0.00              2          1               1   \n",
       "15       3 143129.41              2          0               1   \n",
       "16       1 132602.88              1          1               0   \n",
       "17       9      0.00              2          1               1   \n",
       "18       6      0.00              1          0               0   \n",
       "19       6      0.00              2          1               1   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  \n",
       "5         149756.71       1  \n",
       "6          10062.80       0  \n",
       "7         119346.88       1  \n",
       "8          74940.50       0  \n",
       "9          71725.73       0  \n",
       "10         80181.12       0  \n",
       "11         76390.01       0  \n",
       "12         26260.98       0  \n",
       "13        190857.79       0  \n",
       "14         65951.65       0  \n",
       "15         64327.26       0  \n",
       "16          5097.67       1  \n",
       "17         14406.41       0  \n",
       "18        158684.81       0  \n",
       "19         54724.03       0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
